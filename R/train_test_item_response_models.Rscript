#!/usr/bin/env Rscript

# Validate item response model on participant data with some responses from participants withheld in test splits

# Parse command line arguments
library(argparse)

parser <- ArgumentParser(description = "Validate item response model on participant data with some responses from participants withheld in test splits")
parser$add_argument(
    "--test_individuals_p",
    type = "double",
    default = 0.5,
    help = "Proportion of individuals to use for test data [default: %(default)s]"
)
parser$add_argument(
    "--test_items_p",
    type = "double",
    default = 0.5,
    help = "Proportion of items to use for test data (within test individuals) [default: %(default)s]"
)
parser$add_argument(
    "--n_splits",
    type = "integer",
    default = 1L,
    help = "Number of train-test splits to perform [default: %(default)s]"
)
parser$add_argument(
    "--stan_file",
    type = "character",
    default = "src/stan/credit_model_2cats_v251120.stan",
    help = "Path to Stan model file [default: %(default)s]"
)
parser$add_argument(
    "--dir_data",
    type = "character",
    default = "/Users/or105/Library/CloudStorage/OneDrive-ImperialCollegeLondon/OR_Work/2025/2025_project_Hope_Groups_Jordan/data",
    help = "Directory containing input data files [default: %(default)s]"
)
parser$add_argument(
    "--dir_out",
    type = "character",
    default = "/Users/or105/sandbox/colombia-validate-creditmodel-251125",
    help = "Output directory for results [default: %(default)s]"
)
parser$add_argument(
    "--chains",
    type = "integer",
    default = 2L,
    help = "Number of MCMC chains [default: %(default)s]"
)
parser$add_argument(
    "--parallel_chains",
    type = "integer",
    default = 1L,
    help = "Number of parallel chains [default: %(default)s]"
)
parser$add_argument(
    "--iter_warmup",
    type = "integer",
    default = 500L,
    help = "Number of warmup iterations [default: %(default)s]"
)
parser$add_argument(
    "--iter_sampling",
    type = "integer",
    default = 1500L,
    help = "Number of sampling iterations [default: %(default)s]"
)
parser$add_argument(
    "--seed",
    type = "integer",
    default = 42L,
    help = "Random seed for reproducibility [default: %(default)s]"
)

args <- parser$parse_args()

# Load packages
cat("Loading packages...\n")
packages <- c(
    "data.table",
    "here",
    "ggplot2",
    "ggsci",
    "cmdstanr"
)
invisible(lapply(packages, library, character.only = TRUE))

# Source functions
source(here::here("R", "read_data_colombia.R"))
source(here::here("R", "train_test_split_data.R"))
source(here::here("R", "credit_model_run_analysis.R"))

# Define data locations
file_data <- file.path(args$dir_data, "Colombia_data_baseline_endline_itemised_250927.csv")
if (!file.exists(file_data)) {
    stop("Data file not found: ", file_data)
}

cat("\nConfiguration:\n")
for (arg_name in names(args)) {
    cat(sprintf("  %s: %s\n", arg_name, args[[arg_name]]))
}
cat("\n")

# Load and preprocess data
cat("Loading and preprocessing data...\n")
tmp <- read_data_colombia(file_data)
dp <- copy(tmp$dp)
dit <- copy(tmp$dit)
dmeta <- copy(tmp$dmeta)

dp1 <- subset(dp, !grepl("agg", item_label))
dp1[, time := time + 1L]
dp1[, y_stan := y + 1L]
tmp <- CJ(
    item_label = sort(unique(dp1$item_label)),
    time = unique(dp1$time)
)
tmp[, item_type := ifelse(
    grepl("CG-MH", item_label), "categorical", "out-of-7"
)]
tmp <- tmp[
    , list(
        item_label = item_label, time = time,
        item_time_id = seq_along(item_label)
    ),
    by = "item_type"
]
dp1 <- merge(dp1, tmp, by = c("item_label", "time"))
setkey(dp1, pid, time, item_label)
dp1[, oid := .I]
setkey(dp1, oid)
tmp <- dp1[, list(oid = oid, oidt = seq_along(y_stan)), by = "item_type"]
dp1 <- merge(dp1, tmp, by = c("item_type", "oid"))
setkey(dp1, pid, time, item_label)

cat("Total observations read:", nrow(dp1), "\n\n")


# Perform train-test splits and validation
for (split_idx in seq_len(args$n_splits)) {
    cat("======================================\n")
    cat("Split", split_idx, "of", args$n_splits, "\n")
    cat("======================================\n")

    set.seed(args$seed + split_idx - 1L)
    output_file_prefix <- file.path(args$dir_out, paste0("cm_split", split_idx))

    # Split data
    cat("\nSplitting data...\n")
    tmp <- train_test_split_data(dp1, args$test_individuals_p, args$test_items_p)
    dtest <- copy(tmp$test)
    dtrain <- copy(tmp$train)

    cat(
        "Training observations:", nrow(dtrain),
        sprintf("(%.1f%%)", 100 * nrow(dtrain) / nrow(dp1)), "\n"
    )
    cat(
        "Test observations:", nrow(dtest),
        sprintf("(%.1f%%)", 100 * nrow(dtest) / nrow(dp1)), "\n"
    )

    # Remap PIDs on training data
    tmp <- unique(subset(dtrain, select = c("pid")))
    tmp[, pid_new := .I]
    dtrain <- merge(dtrain, tmp, by = "pid")
    setnames(
        dtrain,
        c("pid", "oid", "oidt", "pid_new"),
        c("pid_orig", "oid_orig", "oidt_orig", "pid")
    )
    dtrain[, oid := seq_len(nrow(dtrain))]
    tmp <- dtrain[, list(oid = oid, oidt = seq_along(y_stan)), by = "item_type"]
    dtrain <- merge(dtrain, tmp, by = c("item_type", "oid"))

    # Remap PIDs on test data
    tmp <- unique(subset(dtrain, select = c("pid", "pid_orig")))
    setnames(tmp, c("pid", "pid_orig"), c("pid_new", "pid"))
    dtest <- merge(dtest, tmp, by = "pid")
    setnames(
        dtest,
        c("pid", "oid", "oidt", "pid_new"),
        c("pid_orig", "oid_orig", "oidt_orig", "pid")
    )
    dtest[, oid := .I]
    tmp <- dtest[, list(oid = oid, oidt = seq_along(y_stan)), by = "item_type"]
    dtest <- merge(dtest, tmp, by = c("item_type", "oid"))

    seed <- args$seed + 100L * split_idx

    # Save train-test split
    cat("\nSaving train-test split...\n")
    save(dtrain, dtest, dit, args, output_file_prefix, seed, file = paste0(output_file_prefix, "_train_test_split.RData"))

    # Fit model on training data
    cat("\nFitting model on training data...\n")
    cm_fit <- credit_model_run_analysis(
        dit,
        dtrain,
        output_file_prefix = paste0(output_file_prefix, "_trainingfit"),
        stan_file = args$stan_file,
        chains = args$chains,
        parallel_chains = args$parallel_chains,
        iter_warmup = args$iter_warmup,
        iter_sampling = args$iter_sampling,
        seed = seed,
        with_core_analyses = FALSE,
        with_additional_analyses = FALSE
    )

    # Prepare test data for Stan
    cat("\nPreparing test data...\n")
    stan_test_data <- list()
    stan_test_data$P <- 1L
    stan_test_data$U <- max(dtrain$pid)
    stan_test_data$Ncat1 <- nrow(dtest[item_type == "categorical", ])
    stan_test_data$Qcat1 <- max(dtest[item_type == "categorical", item_time_id])
    stan_test_data$Kcat1 <- length(unique(dtest[item_type == "categorical", y_stan]))
    stan_test_data$cat1_y <- dtest[item_type == "categorical", y_stan]
    stan_test_data$cat1_question_of_obs <- dtest[
        item_type == "categorical", item_time_id
    ]
    stan_test_data$cat1_unit_of_obs <- dtest[item_type == "categorical", pid]
    stan_test_data$cat1_X <- as.matrix(
        dtest[item_type == "categorical", time - 1L],
        ncol = 1
    )
    stan_test_data$Ncat2 <- nrow(dtest[item_type == "out-of-7", ])
    stan_test_data$Qcat2 <- max(dtest[item_type == "out-of-7", item_time_id])
    stan_test_data$Kcat2 <- length(unique(dtest[item_type == "out-of-7", y_stan]))
    stan_test_data$cat2_y <- dtest[item_type == "out-of-7", y_stan]
    stan_test_data$cat2_question_of_obs <- dtest[
        item_type == "out-of-7", item_time_id
    ]
    stan_test_data$cat2_unit_of_obs <- dtest[item_type == "out-of-7", pid]
    stan_test_data$cat2_X <- as.matrix(
        dtest[item_type == "out-of-7", time - 1L],
        ncol = 1
    )

    # Generate quantities for test data
    cat("Running generate_quantities on test data...\n")
    cm_compiled <- cmdstanr::cmdstan_model(
        args$stan_file,
        include_paths = dirname(args$stan_file)
    )

    # Extract draws and ensure latent_factor_unit sums to zero
    fitted_draws <- cm_fit$draws(format = "draws_matrix")
    lfu_cols <- grep("^latent_factor_unit\\[", colnames(fitted_draws))
    lfu_matrix <- fitted_draws[, lfu_cols]
    row_means <- rowMeans(lfu_matrix)
    fitted_draws[, lfu_cols] <- lfu_matrix - row_means
    fitted_draws_array <- posterior::as_draws_array(fitted_draws)

    # Generate quantities for test data
    cm_test_gq <- cm_compiled$generate_quantities(
        data = stan_test_data,
        fitted_params = fitted_draws_array,
        seed = args$seed + 200L * split_idx
    )

    saveRDS(
        cm_test_gq,
        file = paste0(output_file_prefix, "_test_generated_quantities.rds")
    )
}

# Initialize results storage
results <- list()
for (split_idx in seq_len(args$n_splits)) {
    # Load generated quantities
    output_file_prefix <- file.path(args$dir_out, paste0("cm_split", split_idx))
    cm_test_gq <- readRDS(
        file = paste0(output_file_prefix, "_test_generated_quantities.rds")
    )

    # Extract test data
    load(paste0(output_file_prefix, "_train_test_split.RData"))
    dtest <- copy(dtest)

    # Extract log_lik for test data
    log_lik_matrix <- cm_test_gq$draws("log_lik", format = "matrix")

    # Compute ELPD per 1 test data point
    elpd_test <- mean(
        apply(
            log_lik_matrix,
            2,
            function(ll) {
                ll_loo <- loo::loo_utils_vectorize_log_lik(ll)
                loo::elpd(loo::psis_weights(loo::relative_eff(exp(ll_loo))), ll_loo)
            }
        )
    )

    # Compute proportion of test observations within 95% PPI
    y_test_obs <- dtest$y_stan
    y_test_pred_samples <- cm_test_gq$draws("y_rep", format = "matrix")
    prop_in_ppi <- mean(
        mapply(
            function(y_obs, y_preds) {
                quantiles <- quantile(y_preds, probs = c(0.025, 0.975))
                (y_obs >= quantiles[1]) && (y_obs <= quantiles[2])
            },
            y_obs = y_test_obs,
            as.data.frame(t(y_test_pred_samples))
        )
    )

    # Store results
    results[[split_idx]] <- data.table(
        split_idx = split_idx,
        elpd_test = elpd_test,
        prop_in_ppi = prop_in_ppi
    )

    cat(
        "Split", split_idx, "results:\n",
        "  ELPD per 1 test data point:", elpd_test, "\n",
        "  Proportion in 95% PPI:", prop_in_ppi, "\n\n"
    )
}

# Summarize results across splits
cat("======================================\n")
cat("SUMMARY ACROSS ALL SPLITS\n")
cat("======================================\n")

results_dt <- rbindlist(results)
cat("\nELPD on test data:\n")
cat("  Mean:", mean(results_dt$elpd_test), "\n")
cat("  SD:", sd(results_dt$elpd_test), "\n")
cat("  Min:", min(results_dt$elpd_test), "\n")
cat("  Max:", max(results_dt$elpd_test), "\n")

cat("\nProportion in 95% PPI:\n")
cat("  Mean:", mean(results_dt$prop_in_ppi), "\n")
cat("  SD:", sd(results_dt$prop_in_ppi), "\n")
cat("  Min:", min(results_dt$prop_in_ppi), "\n")
cat("  Max:", max(results_dt$prop_in_ppi), "\n")

# Save summary
saveRDS(results_dt, file = file.path(args$dir_out, "validation_summary.rds"))
write.csv(results_dt, file = file.path(args$dir_out, "validation_summary.csv"), row.names = FALSE)

cat("\nResults saved to:", args$dir_out, "\n")
cat("Validation complete!\n")
