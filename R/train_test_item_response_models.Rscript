#!/usr/bin/env Rscript

# Validate item response model on participant data with some responses from participants withheld in test splits

# Parse command line arguments
library(argparse)
library(jsonlite)

parser <- ArgumentParser(description = "Validate item response model on participant data with some responses from participants withheld in test splits")
parser$add_argument(
    "--json_file",
    type = "character",
    required = TRUE,
    help = "Path to JSON file with input arguments"
)

args <- parser$parse_args()

# Read arguments from JSON file
cat("Reading arguments from JSON file:", args$json_file, "\n")
if (!file.exists(args$json_file)) {
    stop("JSON file not found: ", args$json_file)
}
json_args <- jsonlite::fromJSON(args$json_file)

# Validate that all required arguments are present
required_args <- c(
    "test_individuals_p",
    "test_items_p",
    "n_splits",
    "stan_file",
    "dir_data",
    "dir_out",
    "chains",
    "parallel_chains",
    "iter_warmup",
    "iter_sampling",
    "seed"
)
missing_args <- setdiff(required_args, names(json_args))
if (length(missing_args) > 0) {
    stop(
        "Missing required arguments in JSON file: ",
        paste(missing_args, collapse = ", "),
        "\nRequired arguments are: ",
        paste(required_args, collapse = ", ")
    )
}

# Assign JSON arguments
args <- list(
    test_individuals_p = json_args$test_individuals_p,
    test_items_p = json_args$test_items_p,
    n_splits = as.integer(json_args$n_splits),
    stan_file = json_args$stan_file,
    dir_data = json_args$dir_data,
    dir_out = json_args$dir_out,
    chains = as.integer(json_args$chains),
    parallel_chains = as.integer(json_args$parallel_chains),
    iter_warmup = as.integer(json_args$iter_warmup),
    iter_sampling = as.integer(json_args$iter_sampling),
    seed = as.integer(json_args$seed)
)

# Load packages
cat("Loading packages...\n")
packages <- c(
    "data.table",
    "here",
    "ggplot2",
    "ggsci",
    "cmdstanr"
)
invisible(lapply(packages, library, character.only = TRUE))

# Source functions
source(here::here("R", "read_data_colombia.R"))
source(here::here("R", "train_test_split_data.R"))
source(here::here("R", "credit_model_run_analysis.R"))

# Define data locations
file_data <- file.path(args$dir_data, "Colombia_data_baseline_endline_itemised_250927.csv")
if (!file.exists(file_data)) {
    stop("Data file not found: ", file_data)
}

cat("\nConfiguration:\n")
for (arg_name in names(args)) {
    cat(sprintf("  %s: %s\n", arg_name, args[[arg_name]]))
}
cat("\n")

# Load and preprocess data
cat("Loading and preprocessing data...\n")
tmp <- read_data_colombia(file_data)
dp <- copy(tmp$dp)
dit <- copy(tmp$dit)
dmeta <- copy(tmp$dmeta)

dp1 <- subset(dp, !grepl("agg", item_label))
dp1[, time := time + 1L]
dp1[, y_stan := y + 1L]
tmp <- CJ(
    item_label = sort(unique(dp1$item_label)),
    time = unique(dp1$time)
)
tmp[, item_type := ifelse(
    grepl("CG-MH", item_label), "categorical", "out-of-7"
)]
tmp <- tmp[
    , list(
        item_label = item_label, time = time,
        item_time_id = seq_along(item_label)
    ),
    by = "item_type"
]
dp1 <- merge(dp1, tmp, by = c("item_label", "time"))
setkey(dp1, pid, time, item_label)
dp1[, oid := .I]
setkey(dp1, oid)
tmp <- dp1[, list(oid = oid, oidt = seq_along(y_stan)), by = "item_type"]
dp1 <- merge(dp1, tmp, by = c("item_type", "oid"))
setkey(dp1, pid, time, item_label)

cat("Total observations read:", nrow(dp1), "\n\n")


# Perform train-test splits and validation
for (split_idx in seq_len(args$n_splits)) {
    cat("======================================\n")
    cat("Split", split_idx, "of", args$n_splits, "\n")
    cat("======================================\n")

    set.seed(args$seed + split_idx - 1L)
    output_file_prefix <- file.path(args$dir_out, paste0("cm_split", split_idx))

    # Split data
    cat("\nSplitting data...\n")
    tmp <- train_test_split_data(dp1, args$test_individuals_p, args$test_items_p)
    dtest <- copy(tmp$test)
    dtrain <- copy(tmp$train)

    cat(
        "Training observations:", nrow(dtrain),
        sprintf("(%.1f%%)", 100 * nrow(dtrain) / nrow(dp1)), "\n"
    )
    cat(
        "Test observations:", nrow(dtest),
        sprintf("(%.1f%%)", 100 * nrow(dtest) / nrow(dp1)), "\n"
    )

    # Remap PIDs on training data
    tmp <- unique(subset(dtrain, select = c("pid")))
    tmp[, pid_new := .I]
    dtrain <- merge(dtrain, tmp, by = "pid")
    setnames(
        dtrain,
        c("pid", "oid", "oidt", "pid_new"),
        c("pid_orig", "oid_orig", "oidt_orig", "pid")
    )
    dtrain[, oid := seq_len(nrow(dtrain))]
    tmp <- dtrain[, list(oid = oid, oidt = seq_along(y_stan)), by = "item_type"]
    dtrain <- merge(dtrain, tmp, by = c("item_type", "oid"))

    # Remap PIDs on test data
    tmp <- unique(subset(dtrain, select = c("pid", "pid_orig")))
    setnames(tmp, c("pid", "pid_orig"), c("pid_new", "pid"))
    dtest <- merge(dtest, tmp, by = "pid")
    setnames(
        dtest,
        c("pid", "oid", "oidt", "pid_new"),
        c("pid_orig", "oid_orig", "oidt_orig", "pid")
    )
    dtest[, oid := .I]
    tmp <- dtest[, list(oid = oid, oidt = seq_along(y_stan)), by = "item_type"]
    dtest <- merge(dtest, tmp, by = c("item_type", "oid"))

    seed <- args$seed + 100L * split_idx

    # Save train-test split
    cat("\nSaving train-test split...\n")
    save(dtrain, dtest, dit, args, output_file_prefix, seed, file = paste0(output_file_prefix, "_train_test_split.RData"))

    # Fit model on training data
    cat("\nFitting model on training data...\n")
    cm_fit <- credit_model_run_analysis(
        dit,
        dtrain,
        output_file_prefix = paste0(output_file_prefix, "_trainingfit"),
        stan_file = args$stan_file,
        chains = args$chains,
        parallel_chains = args$parallel_chains,
        iter_warmup = args$iter_warmup,
        iter_sampling = args$iter_sampling,
        seed = seed,
        with_core_analyses = FALSE,
        with_additional_analyses = FALSE
    )

    # Prepare test data for Stan
    cat("\nPreparing test data...\n")
    stan_test_data <- list()
    stan_test_data$P <- 1L
    stan_test_data$U <- max(dtrain$pid)
    stan_test_data$Ncat1 <- nrow(dtest[item_type == "categorical", ])
    stan_test_data$Qcat1 <- max(dtest[item_type == "categorical", item_time_id])
    stan_test_data$Kcat1 <- length(unique(dtest[item_type == "categorical", y_stan]))
    stan_test_data$cat1_y <- dtest[item_type == "categorical", y_stan]
    stan_test_data$cat1_question_of_obs <- dtest[
        item_type == "categorical", item_time_id
    ]
    stan_test_data$cat1_unit_of_obs <- dtest[item_type == "categorical", pid]
    stan_test_data$cat1_X <- as.matrix(
        dtest[item_type == "categorical", time - 1L],
        ncol = 1
    )
    stan_test_data$Ncat2 <- nrow(dtest[item_type == "out-of-7", ])
    stan_test_data$Qcat2 <- max(dtest[item_type == "out-of-7", item_time_id])
    stan_test_data$Kcat2 <- length(unique(dtest[item_type == "out-of-7", y_stan]))
    stan_test_data$cat2_y <- dtest[item_type == "out-of-7", y_stan]
    stan_test_data$cat2_question_of_obs <- dtest[
        item_type == "out-of-7", item_time_id
    ]
    stan_test_data$cat2_unit_of_obs <- dtest[item_type == "out-of-7", pid]
    stan_test_data$cat2_X <- as.matrix(
        dtest[item_type == "out-of-7", time - 1L],
        ncol = 1
    )

    # Generate quantities for test data
    cat("Running generate_quantities on test data...\n")
    cm_compiled <- cmdstanr::cmdstan_model(
        args$stan_file,
        include_paths = dirname(args$stan_file)
    )

    # Extract draws and ensure latent_factor_unit sums to zero
    fitted_draws <- cm_fit$draws(format = "draws_matrix")
    lfu_cols <- grep("^latent_factor_unit\\[", colnames(fitted_draws))
    lfu_matrix <- fitted_draws[, lfu_cols]
    row_means <- rowMeans(lfu_matrix)
    fitted_draws[, lfu_cols] <- lfu_matrix - row_means
    fitted_draws_array <- posterior::as_draws_array(fitted_draws)

    # Generate quantities for test data
    cm_test_gq <- cm_compiled$generate_quantities(
        data = stan_test_data,
        fitted_params = fitted_draws_array,
        seed = args$seed + 200L * split_idx
    )

    saveRDS(
        cm_test_gq,
        file = paste0(output_file_prefix, "_test_generated_quantities.rds")
    )
}

# Initialize results storage
results <- list()
for (split_idx in seq_len(args$n_splits)) {
    # Load generated quantities
    output_file_prefix <- file.path(args$dir_out, paste0("cm_split", split_idx))
    if(file.exists(paste0(output_file_prefix, "_test_generated_quantities.rds"))) {
        cat("Reading file:", paste0(output_file_prefix, "_test_generated_quantities.rds"), "\n")        
        cm_test_gq <- readRDS(
            file = paste0(output_file_prefix, "_test_generated_quantities.rds")
        )

        # Extract test data
        load(paste0(output_file_prefix, "_train_test_split.RData"))
        dtest <- copy(dtest)

        # Extract log_lik for test data
        log_lik_matrix <- cm_test_gq$draws("log_lik", format = "matrix")

        # Compute ELPD per 1 test data point
        elpd_test <- mean(
            apply(
                log_lik_matrix,
                2,
                function(ll) {
                    ll_loo <- loo::loo_utils_vectorize_log_lik(ll)
                    loo::elpd(loo::psis_weights(loo::relative_eff(exp(ll_loo))), ll_loo)
                }
            )
        )

        # Compute proportion of test observations within 95% PPI
        y_test_obs <- dtest$y_stan
        y_test_pred_samples <- cm_test_gq$draws("y_rep", format = "matrix")
        prop_in_ppi <- mean(
            mapply(
                function(y_obs, y_preds) {
                    quantiles <- quantile(y_preds, probs = c(0.025, 0.975))
                    (y_obs >= quantiles[1]) && (y_obs <= quantiles[2])
                },
                y_obs = y_test_obs,
                as.data.frame(t(y_test_pred_samples))
            )
        )

        # Store results
        results[[split_idx]] <- data.table(
            split_idx = split_idx,
            elpd_test = elpd_test,
            prop_in_ppi = prop_in_ppi
        )

        cat(
            "Split", split_idx, "results:\n",
            "  ELPD per 1 test data point:", elpd_test, "\n",
            "  Proportion in 95% PPI:", prop_in_ppi, "\n\n"
        )   
    }
}

# Summarize results across splits
cat("======================================\n")
cat("SUMMARY ACROSS ALL SPLITS\n")
cat("======================================\n")

results_dt <- rbindlist(results)
cat("\nELPD on test data:\n")
cat("  Mean:", mean(results_dt$elpd_test), "\n")
cat("  SD:", sd(results_dt$elpd_test), "\n")
cat("  Min:", min(results_dt$elpd_test), "\n")
cat("  Max:", max(results_dt$elpd_test), "\n")

cat("\nProportion in 95% PPI:\n")
cat("  Mean:", mean(results_dt$prop_in_ppi), "\n")
cat("  SD:", sd(results_dt$prop_in_ppi), "\n")
cat("  Min:", min(results_dt$prop_in_ppi), "\n")
cat("  Max:", max(results_dt$prop_in_ppi), "\n")

# Save summary
saveRDS(results_dt, file = file.path(args$dir_out, "validation_summary.rds"))
write.csv(results_dt, file = file.path(args$dir_out, "validation_summary.csv"), row.names = FALSE)

cat("\nResults saved to:", args$dir_out, "\n")
cat("Validation complete!\n")
